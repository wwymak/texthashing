{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 7714,
     "status": "ok",
     "timestamp": 1521993399739,
     "user": {
      "displayName": "Wendy Mak",
      "photoUrl": "//lh4.googleusercontent.com/-gbReM3_9IvQ/AAAAAAAAAAI/AAAAAAAAARQ/5MZ1FZqa0bI/s50-c-k-no/photo.jpg",
      "userId": "110459131499639239985"
     },
     "user_tz": -60
    },
    "id": "3_CzGJ5DWend",
    "outputId": "3743b43e-fb3a-416e-e288-805927b99009"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Bidirectional, Lambda\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.metrics import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "K2oTuhs0YzOU"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "vTG2UzxPWvmC"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "CFWDM2qIXMT_"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 479,
     "status": "ok",
     "timestamp": 1522001027353,
     "user": {
      "displayName": "Wendy Mak",
      "photoUrl": "//lh4.googleusercontent.com/-gbReM3_9IvQ/AAAAAAAAAAI/AAAAAAAAARQ/5MZ1FZqa0bI/s50-c-k-no/photo.jpg",
      "userId": "110459131499639239985"
     },
     "user_tz": -60
    },
    "id": "H40q1niOVFaN",
    "outputId": "bdcca61d-5df5-4a9a-9a2e-96e1aebf7446"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(index_from=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 1s 1us/step\n"
     ]
    }
   ],
   "source": [
    "word_to_id = imdb.get_word_index()\n",
    "word_to_id = {k:(v+3) for k,v in word_to_id.items()}\n",
    "word_to_id[\"<PAD>\"] = 0\n",
    "word_to_id[\"<START>\"] = 1\n",
    "word_to_id[\"<UNK>\"] = 2\n",
    "\n",
    "id_to_word = {value:key for key,value in word_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_text = [(' '.join(id_to_word[id] for id in x)) for x in list(X_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_text = np.array(X_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "c8ntZ59HXPuo"
   },
   "outputs": [],
   "source": [
    "# !pip install gensim\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "MwFRPcFFMkio"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68,
     "output_extras": [
      {
       "item_id": 3
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3052,
     "status": "ok",
     "timestamp": 1521999056125,
     "user": {
      "displayName": "Wendy Mak",
      "photoUrl": "//lh4.googleusercontent.com/-gbReM3_9IvQ/AAAAAAAAAAI/AAAAAAAAARQ/5MZ1FZqa0bI/s50-c-k-no/photo.jpg",
      "userId": "110459131499639239985"
     },
     "user_tz": -60
    },
    "id": "iHMAUFMEiZLr",
    "outputId": "41776b28-7012-4ebf-efac-88b6bffcc828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Creating gs://dl-models-wwymak/...\n",
      "ServiceException: 409 Bucket dl-models-wwymak already exists.\n"
     ]
    }
   ],
   "source": [
    "project_id = 'data4democracy-wwymak-explore'\n",
    "bucket_name = 'dl-models-wwymak' \n",
    "\n",
    "!gcloud config set project {project_id}\n",
    "# Full reference: https://cloud.google.com/storage/docs/gsutil/commands/mb\n",
    "# !gsutil mb gs://{bucket_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68,
     "output_extras": [
      {
       "item_id": 91
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40408,
     "status": "ok",
     "timestamp": 1521999856095,
     "user": {
      "displayName": "Wendy Mak",
      "photoUrl": "//lh4.googleusercontent.com/-gbReM3_9IvQ/AAAAAAAAAAI/AAAAAAAAARQ/5MZ1FZqa0bI/s50-c-k-no/photo.jpg",
      "userId": "110459131499639239985"
     },
     "user_tz": -60
    },
    "id": "Hlq3byLROMmZ",
    "outputId": "8594aa62-0135-492f-851f-fd2fec352959"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://dl-models-wwymak/GoogleNews-vectors-negative300.bin...\n",
      "\\ [1 files][  3.4 GiB/  3.4 GiB]   89.6 MiB/s                                   \n",
      "Operation completed over 1 objects/3.4 GiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://{bucket_name}/GoogleNews-vectors-negative300.bin /tmp/GoogleNews-vectors-negative300.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W2V_MODEL_PATH='~/models/GoogleNews-vectors-negative300.bin'\n",
    "# W2V_MODEL_PATH='~/code_work/models/GoogleNews-vectors-negative300.bin'\n",
    "# W2V_MODEL_PATH='~/tmp/GoogleNews-vectors-negative300.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 71,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2539,
     "status": "ok",
     "timestamp": 1521999882210,
     "user": {
      "displayName": "Wendy Mak",
      "photoUrl": "//lh4.googleusercontent.com/-gbReM3_9IvQ/AAAAAAAAAAI/AAAAAAAAARQ/5MZ1FZqa0bI/s50-c-k-no/photo.jpg",
      "userId": "110459131499639239985"
     },
     "user_tz": -60
    },
    "id": "hhz7nxg7t3OS",
    "outputId": "2f3b647d-fa59-464c-f4bd-a8c1bcb5dfa2"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(W2V_MODEL_PATH, binary=True, limit=100000)\n",
    "# construct embeeing matrix from word2vec as per \n",
    "# http://www.jacobsilterra.com/2017/05/03/classifying-text-with-keras-basic-text-processing/#Using_Pre-TrainedVectors\n",
    "embedding_matrix = model.vectors\n",
    "# embedding_matrix = model.syn0\n",
    "# Dictionary mapping from word --> row of embedding matrix\n",
    "vocab_dict = {word: model.vocab[word].index for word in model.vocab.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "OjA5IzZYt_Qb"
   },
   "outputs": [],
   "source": [
    "vocab_dim = embedding_matrix.shape[1]# dimensionality of your word vectors\n",
    "n_symbols = embedding_matrix.shape[0]\n",
    "# define inputs here\n",
    "embedding_layer = Embedding(output_dim=vocab_dim, input_dim=n_symbols, trainable=False)\n",
    "embedding_layer.build((None,)) # if you don't do this, the next step won't work\n",
    "embedding_layer.set_weights([embedding_matrix])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "eh6Yw0W72RnV"
   },
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "ORIGINIAL_DIM = 1024 #max number of wrods\n",
    "latent_dim = 100\n",
    "NUM_FEATS_HIDDEN = 256\n",
    "epochs = 50\n",
    "epsilon_std = 1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ssiIbgzytV68"
   },
   "outputs": [],
   "source": [
    "\n",
    "embedding_dim = 300\n",
    "\n",
    "ORIGINIAL_DIM = 1024 #max number of wrods\n",
    "LATENT_DIM = 100 # Latent dimensionality of the encoding space.\n",
    "NUM_FEATS_HIDDEN = 256\n",
    "epochs = 50\n",
    "epsilon_std = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "fdS_fJMj1N_g"
   },
   "outputs": [],
   "source": [
    "# attempt to implement a modified version of \n",
    "# https://github.com/unsuthee/VariationalDeepSemanticHashing/blob/master/VDSH.py\n",
    "# with keras and word2vec vectors\n",
    "class VDSH:\n",
    "    def __init__(self, latent_dim=LATENT_DIM, n_feats_hidden=NUM_FEATS_HIDDEN, original_dim=ORIGINIAL_DIM):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.n_feats_hidden = n_feats_hidden\n",
    "        self.hidden_dim = 500\n",
    "        self.original_dim = original_dim\n",
    "        \n",
    "    def sampling(self,args):\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], self.latent_dim), mean=0.,\n",
    "                                  stddev=epsilon_std)\n",
    "        return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "    \n",
    "    def network(self):\n",
    "        x = Input(shape=(original_dim,))\n",
    "        embedded = embedding_layer(x, name='embedding')\n",
    "        h1 = Dense(self.hidden_dim, activation='relu', name='enc1')(embedded)\n",
    "        h2 = Dense(self.hidden_dim, activation='relu', name='enc2')(h1)\n",
    "        h3 = Dropout(0.3, name='enc3')(h2)\n",
    "        \n",
    "        z_mean = Dense(self.latent_dim, activation='linear', name='z_mean')(h3)\n",
    "        z_log_var = Dense(self.latent_dim, activation='sigmoid',name='z_log_var')(h3)\n",
    "        \n",
    "        z = Lambda(self.sampling)([z_mean, z_log_var])\n",
    "        \n",
    "        decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "        decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "        h_decoded = decoder_h(z)\n",
    "        x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "# instantiate VAE model\n",
    "vae = Model(x, x_decoded_mean)\n",
    "        xent_loss = self.original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n",
    "        kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        vae_loss = K.mean(xent_loss + kl_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "eYagKDxj1PyM"
   },
   "outputs": [],
   "source": [
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "# instantiate VAE model\n",
    "vae = Model(x, x_decoded_mean)\n",
    "\n",
    "# Compute VAE loss\n",
    "xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n",
    "kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "vae_loss = K.mean(xent_loss + kl_loss)\n",
    "\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='rmsprop')\n",
    "vae.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def vae_loss\n",
    "\n",
    "xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n",
    "kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "vae_loss = K.mean(xent_loss + kl_loss)\n",
    "\n",
    "\n",
    "def calc_reconstr_error(self):\n",
    "        # Pick score for those visiable words\n",
    "        p_x_i_scores0 = tf.gather(self.p_x_i, self.input_bow_idx)\n",
    "        weight_scores0 = tf.gather(tf.squeeze(self.input_bow), self.input_bow_idx)\n",
    "        return -tf.reduce_sum(tf.log(tf.maximum(p_x_i_scores0 * weight_scores0, 1e-10)))\n",
    "\n",
    "    def calc_KL_loss(self):\n",
    "        return -0.5 * tf.reduce_sum(tf.reduce_sum(1 + self.z_log_var - tf.square(self.z_mean) \n",
    "                                              - tf.exp(self.z_log_var), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MedianHashing(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.threshold = None\n",
    "        self.latent_dim = None\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self.threshold = np.median(X, axis=0)\n",
    "        self.latent_dim = X.shape[1]\n",
    "        \n",
    "    def transform(self, X):\n",
    "        assert(X.shape[1] == self.latent_dim)\n",
    "        binary_code = np.zeros(X.shape)\n",
    "        for i in range(self.latent_dim):\n",
    "            binary_code[np.nonzero(X[:,i] < self.threshold[i]),i] = 0\n",
    "            binary_code[np.nonzero(X[:,i] >= self.threshold[i]),i] = 1\n",
    "        return binary_code.astype(int)\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "TextHashingAutoencoders.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
