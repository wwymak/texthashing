{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7714,
     "status": "ok",
     "timestamp": 1521993399739,
     "user": {
      "displayName": "Wendy Mak",
      "photoUrl": "//lh4.googleusercontent.com/-gbReM3_9IvQ/AAAAAAAAAAI/AAAAAAAAARQ/5MZ1FZqa0bI/s50-c-k-no/photo.jpg",
      "userId": "110459131499639239985"
     },
     "user_tz": -60
    },
    "id": "3_CzGJ5DWend",
    "outputId": "3743b43e-fb3a-416e-e288-805927b99009"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wendymak/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/wendymak/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Bidirectional, Lambda\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "K2oTuhs0YzOU"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "vTG2UzxPWvmC"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "CFWDM2qIXMT_"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 479,
     "status": "ok",
     "timestamp": 1522001027353,
     "user": {
      "displayName": "Wendy Mak",
      "photoUrl": "//lh4.googleusercontent.com/-gbReM3_9IvQ/AAAAAAAAAAI/AAAAAAAAARQ/5MZ1FZqa0bI/s50-c-k-no/photo.jpg",
      "userId": "110459131499639239985"
     },
     "user_tz": -60
    },
    "id": "H40q1niOVFaN",
    "outputId": "bdcca61d-5df5-4a9a-9a2e-96e1aebf7446"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(index_from=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_id = imdb.get_word_index()\n",
    "word_to_id = {k:(v+3) for k,v in word_to_id.items()}\n",
    "word_to_id[\"<PAD>\"] = 0\n",
    "word_to_id[\"<START>\"] = 1\n",
    "word_to_id[\"<UNK>\"] = 2\n",
    "\n",
    "id_to_word = {value:key for key,value in word_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_text = [(' '.join(id_to_word[id] for id in x)) for x in list(X_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text = np.array(X_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "c8ntZ59HXPuo"
   },
   "outputs": [],
   "source": [
    "# !pip install gensim\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "MwFRPcFFMkio"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68,
     "output_extras": [
      {
       "item_id": 3
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3052,
     "status": "ok",
     "timestamp": 1521999056125,
     "user": {
      "displayName": "Wendy Mak",
      "photoUrl": "//lh4.googleusercontent.com/-gbReM3_9IvQ/AAAAAAAAAAI/AAAAAAAAARQ/5MZ1FZqa0bI/s50-c-k-no/photo.jpg",
      "userId": "110459131499639239985"
     },
     "user_tz": -60
    },
    "id": "iHMAUFMEiZLr",
    "outputId": "41776b28-7012-4ebf-efac-88b6bffcc828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Creating gs://dl-models-wwymak/...\n",
      "ServiceException: 409 Bucket dl-models-wwymak already exists.\n"
     ]
    }
   ],
   "source": [
    "project_id = 'data4democracy-wwymak-explore'\n",
    "bucket_name = 'dl-models-wwymak' \n",
    "\n",
    "!gcloud config set project {project_id}\n",
    "# Full reference: https://cloud.google.com/storage/docs/gsutil/commands/mb\n",
    "# !gsutil mb gs://{bucket_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68,
     "output_extras": [
      {
       "item_id": 91
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40408,
     "status": "ok",
     "timestamp": 1521999856095,
     "user": {
      "displayName": "Wendy Mak",
      "photoUrl": "//lh4.googleusercontent.com/-gbReM3_9IvQ/AAAAAAAAAAI/AAAAAAAAARQ/5MZ1FZqa0bI/s50-c-k-no/photo.jpg",
      "userId": "110459131499639239985"
     },
     "user_tz": -60
    },
    "id": "Hlq3byLROMmZ",
    "outputId": "8594aa62-0135-492f-851f-fd2fec352959"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://dl-models-wwymak/GoogleNews-vectors-negative300.bin...\n",
      "\\ [1 files][  3.4 GiB/  3.4 GiB]   89.6 MiB/s                                   \n",
      "Operation completed over 1 objects/3.4 GiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://{bucket_name}/GoogleNews-vectors-negative300.bin /tmp/GoogleNews-vectors-negative300.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W2V_MODEL_PATH='~/code_work/models/GoogleNews-vectors-negative300.bin'\n",
    "# W2V_MODEL_PATH='~/tmp/GoogleNews-vectors-negative300.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 71,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2539,
     "status": "ok",
     "timestamp": 1521999882210,
     "user": {
      "displayName": "Wendy Mak",
      "photoUrl": "//lh4.googleusercontent.com/-gbReM3_9IvQ/AAAAAAAAAAI/AAAAAAAAARQ/5MZ1FZqa0bI/s50-c-k-no/photo.jpg",
      "userId": "110459131499639239985"
     },
     "user_tz": -60
    },
    "id": "hhz7nxg7t3OS",
    "outputId": "2f3b647d-fa59-464c-f4bd-a8c1bcb5dfa2"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(W2V_MODEL_PATH, binary=True, limit=100000)\n",
    "# construct embeeing matrix from word2vec as per \n",
    "# http://www.jacobsilterra.com/2017/05/03/classifying-text-with-keras-basic-text-processing/#Using_Pre-TrainedVectors\n",
    "embedding_matrix = model.syn0\n",
    "# embedding_matrix = model.wv.vectors\n",
    "# Dictionary mapping from word --> row of embedding matrix\n",
    "vocab_dict = {word: model.vocab[word].index for word in model.vocab.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "OjA5IzZYt_Qb"
   },
   "outputs": [],
   "source": [
    "vocab_dim = embedding_matrix.shape[1]# dimensionality of your word vectors\n",
    "n_symbols = embedding_matrix.shape[0]\n",
    "# define inputs here\n",
    "embedding_layer = Embedding(output_dim=vocab_dim, input_dim=n_symbols, trainable=False)\n",
    "embedding_layer.build((None,)) # if you don't do this, the next step won't work\n",
    "embedding_layer.set_weights([embedding_matrix])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "eh6Yw0W72RnV"
   },
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "original_dim = 1024 #max number of wrods\n",
    "latent_dim = 100\n",
    "intermediate_dim = 256\n",
    "epochs = 50\n",
    "epsilon_std = 1.0\n",
    "\n",
    "x = Input(shape=(original_dim,))\n",
    "\n",
    "embedded = embedding_layer(x)\n",
    "h = Dense(intermediate_dim, activation='relu')(embedded)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "9Pkt50eH3Ksp"
   },
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "m5oRhQNg8lIu"
   },
   "outputs": [],
   "source": [
    "z = Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "# we instantiate these layers separately so as to reuse them later\n",
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "# instantiate VAE model\n",
    "vae = Model(x, x_decoded_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ssiIbgzytV68"
   },
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "embedding_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "fdS_fJMj1N_g"
   },
   "outputs": [],
   "source": [
    "# attempt to implement a modified version of \n",
    "# https://github.com/unsuthee/VariationalDeepSemanticHashing/blob/master/VDSH.py\n",
    "# with keras and word2vec vectors\n",
    "class VDSH:\n",
    "    def __init__(self, latent_dim, n_feats_hidden):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.n_feats_hidden = n_feats_hidden\n",
    "    \n",
    "    def network(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "eYagKDxj1PyM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JEJyoIt6tXnr"
   },
   "outputs": [],
   "source": [
    "def network():\n",
    "  encoder_inputs = Input(shape=(None, 300))\n",
    "  encoder = LSTM(latent_dim, return_state=True)\n",
    "  encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "  encoder_states = [state_h, state_c]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "TextHashingAutoencoders.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
